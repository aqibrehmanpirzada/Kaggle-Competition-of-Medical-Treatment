{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##                           <p>           Kaggle PROJECT    </p>\n",
    "\n",
    "#                          Project : Medical Treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot has been said during the past several years about how precision medicine and, more concretely, how genetic testing is going to disrupt the way diseases like cancer are treated.\n",
    "\n",
    "But this is only partially happening due to the huge amount of manual work still required. Once sequenced, a cancer tumor can have thousands of genetic mutations. But the challenge is distinguishing the mutations that contribute to tumor growth (drivers) from the neutral mutations (passengers). \n",
    "\n",
    "Currently this interpretation of genetic mutations is being done manually. This is a very time-consuming task where a clinical pathologist has to manually review and classify every single genetic mutation based on evidence from text-based clinical literature.\n",
    "\n",
    "We need to develop a Machine Learning algorithm that, using this knowledge base as a baseline, automatically classifies genetic variations.\n",
    "\n",
    "This problem was a competition posted on Kaggle with a award of $15,000. This was launched by  Memorial Sloan Kettering Cancer Center (MSKCC), accepted by NIPS 2017 Competition Track,  because we need your help to take personalized medicine to its full potential.\n",
    "\n",
    "You can check all details about the competition from following link :\n",
    "https://www.kaggle.com/c/msk-redefining-cancer-treatment\n",
    "\n",
    "In order to get the dataset please create a login account to Kaggle and go to this problem statement page(given above) and download 2 dataset\n",
    "\n",
    "***training_variants.zip*** and ***training_text.zip***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first understand the data set provided and using that dataset we will try to understand the above problem in Machine Learning world. Since, the dataset is huge lets load it using python itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/aqib/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Loading all required packages\n",
    "# If any of it fails, do not panic. Just install it using \"pip3 install <package_name>\" or by using conda install package_name\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "import re\n",
    "import time\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import warnings\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from collections import Counter\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import math\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 data files provided for solving this problem. I have kept them inside a folder training. So lets load them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading training_variants. Its a comma seperated file\n",
    "data_variants = pd.read_csv('training_variants')\n",
    "# Loading training_text dataset. This is seperated by ||\n",
    "data_text =pd.read_csv(\"training_text\",sep=\"\\|\\|\",engine=\"python\",names=[\"ID\",\"TEXT\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FAM58A</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CBL</td>\n",
       "      <td>W802*</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CBL</td>\n",
       "      <td>Q249E</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID    Gene             Variation  Class\n",
       "0   0  FAM58A  Truncating Mutations      1\n",
       "1   1     CBL                 W802*      2\n",
       "2   2     CBL                 Q249E      2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_variants.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    Let's understand above data. There are 4 fields above: <br>\n",
    "    <ul>\n",
    "        <li><b>ID : </b>row id used to link the mutation to the clinical evidence</li>\n",
    "        <li><b>Gene : </b>the gene where this genetic mutation is located </li>\n",
    "        <li><b>Variation : </b>the aminoacid change for this mutations </li>\n",
    "        <li><b>Class :</b> class value 1-9, this genetic mutation has been classified on</li>\n",
    "    </ul>\n",
    "    \n",
    "Keep doing more analysis  on above data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3321 entries, 0 to 3320\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   ID         3321 non-null   int64 \n",
      " 1   Gene       3321 non-null   object\n",
      " 2   Variation  3321 non-null   object\n",
      " 3   Class      3321 non-null   int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 103.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data_variants.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3321.000000</td>\n",
       "      <td>3321.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1660.000000</td>\n",
       "      <td>4.365854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>958.834449</td>\n",
       "      <td>2.309781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>830.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1660.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2490.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3320.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID        Class\n",
       "count  3321.000000  3321.000000\n",
       "mean   1660.000000     4.365854\n",
       "std     958.834449     2.309781\n",
       "min       0.000000     1.000000\n",
       "25%     830.000000     2.000000\n",
       "50%    1660.000000     4.000000\n",
       "75%    2490.000000     7.000000\n",
       "max    3320.000000     9.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_variants.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3321, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking dimention of data\n",
    "data_variants.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Gene', 'Variation', 'Class'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clecking column in above data set\n",
    "data_variants.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets explore about data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Cyclin-dependent kinases (CDKs) regulate a var...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               TEXT\n",
       "0   0  Cyclin-dependent kinases (CDKs) regulate a var...\n",
       "1   1   Abstract Background  Non-small cell lung canc...\n",
       "2   2   Abstract Background  Non-small cell lung canc..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_text.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So above dataset have 2 columns. ID and Text column. We can also observe column ID which is common in both the dataset. Lets keep exploring it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3321 entries, 0 to 3320\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ID      3321 non-null   int64 \n",
      " 1   TEXT    3316 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 52.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data_text.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3321.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1660.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>958.834449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>830.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1660.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2490.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3320.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID\n",
       "count  3321.000000\n",
       "mean   1660.000000\n",
       "std     958.834449\n",
       "min       0.000000\n",
       "25%     830.000000\n",
       "50%    1660.000000\n",
       "75%    2490.000000\n",
       "max    3320.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_text.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'TEXT'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_text.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3321, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the dimentions\n",
    "data_text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, in short my datasets looks like this\n",
    " * data_variants (ID, Gene, Variations, Class)\n",
    " * data_text(ID, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now we understood the dataset. Lets try to understand the same problem from Machine Learning point of view\n",
    "\n",
    "We want to predict about class of cancer. Now question is what kind of data is present in class column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_variants.Class.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is descrete data so it is ***classification*** problem and since there are multiple descrete output possible so we can call it ***Multi class*** classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Important note*** : This is medical related problem so correct results are very important. Error can be really costly here so we would like to have result  for each class in terms of Probablity. We might not be much bothered about time taken by ML algorithm as far as it is reasonable. \n",
    "\n",
    "We also want our model to be highly interpritable because a medical practitionar want to also give proper reasonining on why ML algorithm is predicting any class. \n",
    "\n",
    "We will evaluate our model using Confution matrix and Multi class log-loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now we understood the problem statement. Let's work on the solution. \n",
    "\n",
    "***Note*** I highly recomend you to attempt the solution on your own first. After that come back and enjoy our solution. \n",
    "\n",
    "We have huge amount of text data. So, we need to pre process it. So lets write a function for the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We would like to remove all stop words like a, is, an, the, ... \n",
    "# so we collecting all of them from nltk library\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_text_preprocess(total_text, ind, col):\n",
    "    # Remove int values from text data as that might not be imp\n",
    "    if type(total_text) is not int:\n",
    "        string = \"\"\n",
    "        # replacing all special char with space\n",
    "        total_text = re.sub('[^a-zA-Z0-9\\n]', ' ', str(total_text))\n",
    "        # replacing multiple spaces with single space\n",
    "        total_text = re.sub('\\s+',' ', str(total_text))\n",
    "        # bring whole text to same lower-case scale.\n",
    "        total_text = total_text.lower()\n",
    "        \n",
    "        for word in total_text.split():\n",
    "        # if the word is a not a stop word then retain that word from text\n",
    "            if not word in stop_words:\n",
    "                string += word + \" \"\n",
    "        \n",
    "        data_text[col][ind] = string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below code will take some time because its huge text (took 4 minute on my 16 GB RAM system), so run it and have a cup of coffee :)\n",
    "for index, row in data_text.iterrows():\n",
    "    if type(row['TEXT']) is str:\n",
    "        data_text_preprocess(row['TEXT'], index, 'TEXT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's merge both the dataset. Remember that ID was common column. So lets use it to merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Class</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FAM58A</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "      <td>1</td>\n",
       "      <td>cyclin dependent kinases cdks regulate variety...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CBL</td>\n",
       "      <td>W802*</td>\n",
       "      <td>2</td>\n",
       "      <td>abstract background non small cell lung cancer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CBL</td>\n",
       "      <td>Q249E</td>\n",
       "      <td>2</td>\n",
       "      <td>abstract background non small cell lung cancer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CBL</td>\n",
       "      <td>N454D</td>\n",
       "      <td>3</td>\n",
       "      <td>recent evidence demonstrated acquired uniparen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CBL</td>\n",
       "      <td>L399V</td>\n",
       "      <td>4</td>\n",
       "      <td>oncogenic mutations monomeric casitas b lineag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID    Gene             Variation  Class  \\\n",
       "0   0  FAM58A  Truncating Mutations      1   \n",
       "1   1     CBL                 W802*      2   \n",
       "2   2     CBL                 Q249E      2   \n",
       "3   3     CBL                 N454D      3   \n",
       "4   4     CBL                 L399V      4   \n",
       "\n",
       "                                                TEXT  \n",
       "0  cyclin dependent kinases cdks regulate variety...  \n",
       "1  abstract background non small cell lung cancer...  \n",
       "2  abstract background non small cell lung cancer...  \n",
       "3  recent evidence demonstrated acquired uniparen...  \n",
       "4  oncogenic mutations monomeric casitas b lineag...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merging both gene_variations and text data based on ID\n",
    "result = pd.merge(data_variants, data_text,on='ID', how='left')\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's very important to look for missing values. Else they create problem in final analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Class</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>1109</td>\n",
       "      <td>FANCA</td>\n",
       "      <td>S1088F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>1277</td>\n",
       "      <td>ARID5B</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>1407</td>\n",
       "      <td>FGFR3</td>\n",
       "      <td>K508M</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>1639</td>\n",
       "      <td>FLT1</td>\n",
       "      <td>Amplification</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2755</th>\n",
       "      <td>2755</td>\n",
       "      <td>BRAF</td>\n",
       "      <td>G596C</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID    Gene             Variation  Class TEXT\n",
       "1109  1109   FANCA                S1088F      1  NaN\n",
       "1277  1277  ARID5B  Truncating Mutations      1  NaN\n",
       "1407  1407   FGFR3                 K508M      6  NaN\n",
       "1639  1639    FLT1         Amplification      6  NaN\n",
       "2755  2755    BRAF                 G596C      7  NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[result.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see many rows with missing data. Now the question is what to do with this missing value. One way could be that we can drop these rows having missing values or we can do some imputation in it. Let's go with imputation only. But question is what to impute here :\n",
    "\n",
    "How about merging Gene and Variation column. Let's do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.loc[result['TEXT'].isnull(),'TEXT'] = result['Gene'] +' '+result['Variation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's cross check it once again if there is any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Class</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ID, Gene, Variation, Class, TEXT]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[result.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome, so all missing values are gone now.\n",
    "\n",
    "## Creating Training, Test and Validation data\n",
    "\n",
    "Before we split the data into taining, test and validation data set. We want to ensure that all spaces in Gene and Variation column to be replaced by _."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = result['Class'].values\n",
    "result.Gene      = result.Gene.str.replace('\\s+', '_')\n",
    "result.Variation = result.Variation.str.replace('\\s+', '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we can now start our split process in train, test and validation data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test set \n",
    "X_train, test_df, y_train, y_test = train_test_split(result, y_true, stratify=y_true, test_size=0.2)\n",
    "# split the train data now into train validation and cross validation\n",
    "train_df, cv_df, y_train, y_cv = train_test_split(X_train, y_train, stratify=y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points in train data: 2124\n",
      "Number of data points in test data: 665\n",
      "Number of data points in cross validation data: 532\n"
     ]
    }
   ],
   "source": [
    "print('Number of data points in train data:', train_df.shape[0])\n",
    "print('Number of data points in test data:', test_df.shape[0])\n",
    "print('Number of data points in cross validation data:', cv_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the distribution of data in train, test and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'sort_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-209a44c22ad1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_SparseArray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"module 'pandas' has no attribute '{name}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'sort_values'"
     ]
    }
   ],
   "source": [
    "pd.sort_values()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class_distribution = train_df['Class'].value_counts().sort_index()\n",
    "test_class_distribution = test_df['Class'].value_counts().sort_index()\n",
    "cv_class_distribution = cv_df['Class'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what does above variable suggest us. This means in my train dataset we have class 1 values with count of 363, class 2 values having count of 289 and so on. It will be better idea to visualise it in graph format.\n",
    "\n",
    "*** Visualizing for train class distrubution***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_colors = 'rgbkymc'\n",
    "train_class_distribution.plot(kind='bar')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel(' Number of Data points per Class')\n",
    "plt.title('Distribution of yi in train data')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at distribution in form of percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_yi = np.argsort(-train_class_distribution.values)\n",
    "for i in sorted_yi:\n",
    "    print('Number of data points in class', i+1, ':',train_class_distribution.values[i], '(', np.round((train_class_distribution.values[i]/train_df.shape[0]*100), 3), '%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the same for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_colors = 'rgbkymc'\n",
    "test_class_distribution.plot(kind='bar')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Data points per Class')\n",
    "plt.title('Distribution of yi in test data')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_yi = np.argsort(-test_class_distribution.values)\n",
    "for i in sorted_yi:\n",
    "    print('Number of data points in class', i+1, ':',test_class_distribution.values[i], '(', np.round((test_class_distribution.values[i]/test_df.shape[0]*100), 3), '%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize for cross validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_colors = 'rgbkymc'\n",
    "cv_class_distribution.plot(kind='bar')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Data points per Class')\n",
    "plt.title('Distribution of yi in cross validation data')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_yi = np.argsort(-train_class_distribution.values)\n",
    "for i in sorted_yi:\n",
    "    print('Number of data points in class', i+1, ':',cv_class_distribution.values[i], '(', np.round((cv_class_distribution.values[i]/cv_df.shape[0]*100), 3), '%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now question is because we need log-loss as final evaluation metrics how do we say that model we are going to build will be good model. For doing this we will build a random model and will evaluate log loss. Our model should return lower log loss value than this. So, what are you waiting for. Always have a bg smile while solving Machine learning problems :). That helps!!\n",
    "\n",
    "## Building a Random model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we need to generate 9 random numbers because we have 9 class such that their sum must be equal to 1 because sum of Probablity of all 9 classes must be equivalent to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_len = test_df.shape[0]\n",
    "cv_data_len = cv_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a output array that has exactly same size as the CV data\n",
    "cv_predicted_y = np.zeros((cv_data_len,9))\n",
    "for i in range(cv_data_len):\n",
    "    rand_probs = np.random.rand(1,9)\n",
    "    cv_predicted_y[i] = ((rand_probs/sum(sum(rand_probs)))[0])\n",
    "print(\"Log loss on Cross Validation Data using Random Model\",log_loss(y_cv,cv_predicted_y, eps=1e-15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-Set error.\n",
    "#we create a output array that has exactly same as the test data\n",
    "test_predicted_y = np.zeros((test_data_len,9))\n",
    "for i in range(test_data_len):\n",
    "    rand_probs = np.random.rand(1,9)\n",
    "    test_predicted_y[i] = ((rand_probs/sum(sum(rand_probs)))[0])\n",
    "print(\"Log loss on Test Data using Random Model\",log_loss(y_test,test_predicted_y, eps=1e-15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets get the index of max probablity\n",
    "predicted_y =np.argmax(test_predicted_y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see the output. these will be 665 values present in test dataset\n",
    "predicted_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you can see the index value ranging from 0 to 8. So, lets make it as 1 to 9 we will increase this value by 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y = predicted_y + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = confusion_matrix(y_test, predicted_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [1,2,3,4,5,6,7,8,9]\n",
    "plt.figure(figsize=(20,7))\n",
    "sns.heatmap(C, annot=True, cmap=\"YlGnBu\", fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('Original Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B =(C/C.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,7))\n",
    "sns.heatmap(B, annot=True, cmap=\"YlGnBu\", fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('Original Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A =(((C.T)/(C.sum(axis=1))).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,7))\n",
    "sns.heatmap(A, annot=True, cmap=\"YlGnBu\", fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('Original Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Gene Column\n",
    "\n",
    "Now we will look at each independent column to make sure its relavent for my target variable but the question is, how? Let's understand with our first column Gene which is categorial in nature.\n",
    "\n",
    "So, lets explore column ***Gene*** and lets look at its distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_genes = train_df['Gene'].value_counts()\n",
    "print('Number of Unique Genes :', unique_genes.shape[0])\n",
    "# the top 10 genes that occured most\n",
    "print(unique_genes.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see the number of unique values present in gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_genes.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the comulative distribution of unique Genes values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sum(unique_genes.values);\n",
    "h = unique_genes.values/s;\n",
    "c = np.cumsum(h)\n",
    "plt.plot(c,label='Cumulative distribution of Genes')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now we need to convert these categorical variable to appropirate format which my machine learning algorithm will be able to take as an input.\n",
    "\n",
    "So we have 2 techniques to deal with it. \n",
    "\n",
    "<ol><li>\n",
    "     ***One-hot encoding*** </li>\n",
    "    <li> ***Response Encoding*** (Mean imputation) </li>\n",
    "</ol>\n",
    "\n",
    "Let's use both of them to see which one work the best. So lets start encoding using one hot encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding of Gene feature.\n",
    "gene_vectorizer = CountVectorizer()\n",
    "train_gene_feature_onehotCoding = gene_vectorizer.fit_transform(train_df['Gene'])\n",
    "test_gene_feature_onehotCoding = gene_vectorizer.transform(test_df['Gene'])\n",
    "cv_gene_feature_onehotCoding = gene_vectorizer.transform(cv_df['Gene'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the number of column generated after one hot encoding. One hot encoding will always return higher number of column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gene_feature_onehotCoding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column names after one-hot encoding for Gene column\n",
    "gene_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets also create Response encoding columns for Gene column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for response coding with Laplace smoothing.\n",
    "# alpha : used for laplace smoothing\n",
    "# feature: ['gene', 'variation']\n",
    "# df: ['train_df', 'test_df', 'cv_df']\n",
    "# algorithm\n",
    "# ----------\n",
    "# Consider all unique values and the number of occurances of given feature in train data dataframe\n",
    "# build a vector (1*9) , the first element = (number of times it occured in class1 + 10*alpha / number of time it occurred in total data+90*alpha)\n",
    "# gv_dict is like a look up table, for every gene it store a (1*9) representation of it\n",
    "# for a value of feature in df:\n",
    "# if it is in train data:\n",
    "# we add the vector that was stored in 'gv_dict' look up table to 'gv_fea'\n",
    "# if it is not there is train:\n",
    "# we add [1/9, 1/9, 1/9, 1/9,1/9, 1/9, 1/9, 1/9, 1/9] to 'gv_fea'\n",
    "# return 'gv_fea'\n",
    "# ----------------------\n",
    "\n",
    "# get_gv_fea_dict: Get Gene varaition Feature Dict\n",
    "def get_gv_fea_dict(alpha, feature, df):\n",
    "    # value_count: it contains a dict like\n",
    "    # print(train_df['Gene'].value_counts())\n",
    "    # output:\n",
    "    #        {BRCA1      174\n",
    "    #         TP53       106\n",
    "    #         EGFR        86\n",
    "    #         BRCA2       75\n",
    "    #         PTEN        69\n",
    "    #         KIT         61\n",
    "    #         BRAF        60\n",
    "    #         ERBB2       47\n",
    "    #         PDGFRA      46\n",
    "    #         ...}\n",
    "    # print(train_df['Variation'].value_counts())\n",
    "    # output:\n",
    "    # {\n",
    "    # Truncating_Mutations                     63\n",
    "    # Deletion                                 43\n",
    "    # Amplification                            43\n",
    "    # Fusions                                  22\n",
    "    # Overexpression                            3\n",
    "    # E17K                                      3\n",
    "    # Q61L                                      3\n",
    "    # S222D                                     2\n",
    "    # P130S                                     2\n",
    "    # ...\n",
    "    # }\n",
    "    value_count = train_df[feature].value_counts()\n",
    "    \n",
    "    # gv_dict : Gene Variation Dict, which contains the probability array for each gene/variation\n",
    "    gv_dict = dict()\n",
    "    \n",
    "    # denominator will contain the number of time that particular feature occured in whole data\n",
    "    for i, denominator in value_count.items():\n",
    "        # vec will contain (p(yi==1/Gi) probability of gene/variation belongs to perticular class\n",
    "        # vec is 9 diamensional vector\n",
    "        vec = []\n",
    "        for k in range(1,10):\n",
    "            # print(train_df.loc[(train_df['Class']==1) & (train_df['Gene']=='BRCA1')])\n",
    "            #         ID   Gene             Variation  Class  \n",
    "            # 2470  2470  BRCA1                S1715C      1   \n",
    "            # 2486  2486  BRCA1                S1841R      1   \n",
    "            # 2614  2614  BRCA1                   M1R      1   \n",
    "            # 2432  2432  BRCA1                L1657P      1   \n",
    "            # 2567  2567  BRCA1                T1685A      1   \n",
    "            # 2583  2583  BRCA1                E1660G      1   \n",
    "            # 2634  2634  BRCA1                W1718L      1   \n",
    "            # cls_cnt.shape[0] will return the number of rows\n",
    "\n",
    "            cls_cnt = train_df.loc[(train_df['Class']==k) & (train_df[feature]==i)]\n",
    "            \n",
    "            # cls_cnt.shape[0](numerator) will contain the number of time that particular feature occured in whole data\n",
    "            vec.append((cls_cnt.shape[0] + alpha*10)/ (denominator + 90*alpha))\n",
    "\n",
    "        # we are adding the gene/variation to the dict as key and vec as value\n",
    "        gv_dict[i]=vec\n",
    "    return gv_dict\n",
    "\n",
    "# Get Gene variation feature\n",
    "def get_gv_feature(alpha, feature, df):\n",
    "    # print(gv_dict)\n",
    "    #     {'BRCA1': [0.20075757575757575, 0.03787878787878788, 0.068181818181818177, 0.13636363636363635, 0.25, 0.19318181818181818, 0.03787878787878788, 0.03787878787878788, 0.03787878787878788], \n",
    "    #      'TP53': [0.32142857142857145, 0.061224489795918366, 0.061224489795918366, 0.27040816326530615, 0.061224489795918366, 0.066326530612244902, 0.051020408163265307, 0.051020408163265307, 0.056122448979591837], \n",
    "    #      'EGFR': [0.056818181818181816, 0.21590909090909091, 0.0625, 0.068181818181818177, 0.068181818181818177, 0.0625, 0.34659090909090912, 0.0625, 0.056818181818181816], \n",
    "    #      'BRCA2': [0.13333333333333333, 0.060606060606060608, 0.060606060606060608, 0.078787878787878782, 0.1393939393939394, 0.34545454545454546, 0.060606060606060608, 0.060606060606060608, 0.060606060606060608], \n",
    "    #      'PTEN': [0.069182389937106917, 0.062893081761006289, 0.069182389937106917, 0.46540880503144655, 0.075471698113207544, 0.062893081761006289, 0.069182389937106917, 0.062893081761006289, 0.062893081761006289], \n",
    "    #      'KIT': [0.066225165562913912, 0.25165562913907286, 0.072847682119205295, 0.072847682119205295, 0.066225165562913912, 0.066225165562913912, 0.27152317880794702, 0.066225165562913912, 0.066225165562913912], \n",
    "    #      'BRAF': [0.066666666666666666, 0.17999999999999999, 0.073333333333333334, 0.073333333333333334, 0.093333333333333338, 0.080000000000000002, 0.29999999999999999, 0.066666666666666666, 0.066666666666666666],\n",
    "    #      ...\n",
    "    #     }\n",
    "    gv_dict = get_gv_fea_dict(alpha, feature, df)\n",
    "    # value_count is similar in get_gv_fea_dict\n",
    "    value_count = train_df[feature].value_counts()\n",
    "    \n",
    "    # gv_fea: Gene_variation feature, it will contain the feature for each feature value in the data\n",
    "    gv_fea = []\n",
    "    # for every feature values in the given data frame we will check if it is there in the train data then we will add the feature to gv_fea\n",
    "    # if not we will add [1/9,1/9,1/9,1/9,1/9,1/9,1/9,1/9,1/9] to gv_fea\n",
    "    for index, row in df.iterrows():\n",
    "        if row[feature] in dict(value_count).keys():\n",
    "            gv_fea.append(gv_dict[row[feature]])\n",
    "        else:\n",
    "            gv_fea.append([1/9,1/9,1/9,1/9,1/9,1/9,1/9,1/9,1/9])\n",
    "#             gv_fea.append([-1,-1,-1,-1,-1,-1,-1,-1,-1])\n",
    "    return gv_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#response-coding of the Gene feature\n",
    "# alpha is used for laplace smoothing\n",
    "alpha = 1\n",
    "# train gene feature\n",
    "train_gene_feature_responseCoding = np.array(get_gv_feature(alpha, \"Gene\", train_df))\n",
    "# test gene feature\n",
    "test_gene_feature_responseCoding = np.array(get_gv_feature(alpha, \"Gene\", test_df))\n",
    "# cross validation gene feature\n",
    "cv_gene_feature_responseCoding = np.array(get_gv_feature(alpha, \"Gene\", cv_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at columns after applying response encoding. We must be having 9 columns for Gene column after response encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gene_feature_responseCoding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, question is how good is Gene column feature to predict my 9 classes. One idea could be that we will build model having only gene column with one hot encoder with simple model like Logistic regression. If log loss with only one column Gene comes out to be better than random model, than this feature is important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need a hyperparemeter for SGD classifier.\n",
    "alpha = [10 ** x for x in range(-5, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be using SGD classifier\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "# We will also be using Calibrated Classifier to get the result into probablity format t be used for log loss\n",
    "cv_log_error_array=[]\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(alpha=i, penalty='l2', loss='log', random_state=42)\n",
    "    clf.fit(train_gene_feature_onehotCoding, y_train)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(train_gene_feature_onehotCoding, y_train)\n",
    "    predict_y = sig_clf.predict_proba(cv_gene_feature_onehotCoding)\n",
    "    cv_log_error_array.append(log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "    print('For values of alpha = ', i, \"The log loss is:\",log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets plot the same to check the best Alpha value\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, cv_log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(cv_log_error_array,3)):\n",
    "    ax.annotate((alpha[i],np.round(txt,3)), (alpha[i],cv_log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets use best alpha value as we can see from above graph and compute log loss\n",
    "best_alpha = np.argmin(cv_log_error_array)\n",
    "clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='log', random_state=42)\n",
    "clf.fit(train_gene_feature_onehotCoding, y_train)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(train_gene_feature_onehotCoding, y_train)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(train_gene_feature_onehotCoding)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(cv_gene_feature_onehotCoding)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The cross validation log loss is:\",log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(test_gene_feature_onehotCoding)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(y_test, predict_y, labels=clf.classes_, eps=1e-15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets check how many values are overlapping between train, test or between CV and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_coverage=test_df[test_df['Gene'].isin(list(set(train_df['Gene'])))].shape[0]\n",
    "cv_coverage=cv_df[cv_df['Gene'].isin(list(set(train_df['Gene'])))].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('1. In test data',test_coverage, 'out of',test_df.shape[0], \":\",(test_coverage/test_df.shape[0])*100)\n",
    "print('2. In cross validation data',cv_coverage, 'out of ',cv_df.shape[0],\":\" ,(cv_coverage/cv_df.shape[0])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Variation column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variation is also a categorical variable so we have to deal in same way like we have done for ***Gene*** column. We will again get the one hot encoder and response enoding variable for variation column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_variations = train_df['Variation'].value_counts()\n",
    "print('Number of Unique Variations :', unique_variations.shape[0])\n",
    "# the top 10 variations that occured most\n",
    "print(unique_variations.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the comulative distribution of unique ***variation*** values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sum(unique_variations.values);\n",
    "h = unique_variations.values/s;\n",
    "c = np.cumsum(h)\n",
    "print(c)\n",
    "plt.plot(c,label='Cumulative distribution of Variations')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets convert the variation column using one hot encoder column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding of variation feature.\n",
    "variation_vectorizer = CountVectorizer()\n",
    "train_variation_feature_onehotCoding = variation_vectorizer.fit_transform(train_df['Variation'])\n",
    "test_variation_feature_onehotCoding = variation_vectorizer.transform(test_df['Variation'])\n",
    "cv_variation_feature_onehotCoding = variation_vectorizer.transform(cv_df['Variation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at shape of one hot encoder column for variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_variation_feature_onehotCoding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do the same for variation column and generate response encoding for the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha is used for laplace smoothing\n",
    "alpha = 1\n",
    "# train gene feature\n",
    "train_variation_feature_responseCoding = np.array(get_gv_feature(alpha, \"Variation\", train_df))\n",
    "# test gene feature\n",
    "test_variation_feature_responseCoding = np.array(get_gv_feature(alpha, \"Variation\", test_df))\n",
    "# cross validation gene feature\n",
    "cv_variation_feature_responseCoding = np.array(get_gv_feature(alpha, \"Variation\", cv_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the shape of this response encoding result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_variation_feature_responseCoding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets again build the model with only column name of ***variation*** column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need a hyperparemeter for SGD classifier.\n",
    "alpha = [10 ** x for x in range(-5, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be using SGD classifier\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "# We will also be using Calibrated Classifier to get the result into probablity format t be used for log loss\n",
    "cv_log_error_array=[]\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(alpha=i, penalty='l2', loss='log', random_state=42)\n",
    "    clf.fit(train_variation_feature_onehotCoding, y_train)\n",
    "    \n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(train_variation_feature_onehotCoding, y_train)\n",
    "    predict_y = sig_clf.predict_proba(cv_variation_feature_onehotCoding)\n",
    "    \n",
    "    cv_log_error_array.append(log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "    print('For values of alpha = ', i, \"The log loss is:\",log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets plot the same to check the best Alpha value\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, cv_log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(cv_log_error_array,3)):\n",
    "    ax.annotate((alpha[i],np.round(txt,3)), (alpha[i],cv_log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha = np.argmin(cv_log_error_array)\n",
    "clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='log', random_state=42)\n",
    "clf.fit(train_variation_feature_onehotCoding, y_train)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(train_variation_feature_onehotCoding, y_train)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(train_variation_feature_onehotCoding)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(cv_variation_feature_onehotCoding)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The cross validation log loss is:\",log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(test_variation_feature_onehotCoding)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(y_test, predict_y, labels=clf.classes_, eps=1e-15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_coverage=test_df[test_df['Variation'].isin(list(set(train_df['Variation'])))].shape[0]\n",
    "cv_coverage=cv_df[cv_df['Variation'].isin(list(set(train_df['Variation'])))].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('1. In test data',test_coverage, 'out of',test_df.shape[0], \":\",(test_coverage/test_df.shape[0])*100)\n",
    "print('2. In cross validation data',cv_coverage, 'out of ',cv_df.shape[0],\":\" ,(cv_coverage/cv_df.shape[0])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cls_text is a data frame\n",
    "# for every row in data fram consider the 'TEXT'\n",
    "# split the words by space\n",
    "# make a dict with those words\n",
    "# increment its count whenever we see that word\n",
    "\n",
    "def extract_dictionary_paddle(cls_text):\n",
    "    dictionary = defaultdict(int)\n",
    "    for index, row in cls_text.iterrows():\n",
    "        for word in row['TEXT'].split():\n",
    "            dictionary[word] +=1\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "#https://stackoverflow.com/a/1602964\n",
    "def get_text_responsecoding(df):\n",
    "    text_feature_responseCoding = np.zeros((df.shape[0],9))\n",
    "    for i in range(0,9):\n",
    "        row_index = 0\n",
    "        for index, row in df.iterrows():\n",
    "            sum_prob = 0\n",
    "            for word in row['TEXT'].split():\n",
    "                sum_prob += math.log(((dict_list[i].get(word,0)+10 )/(total_dict.get(word,0)+90)))\n",
    "            text_feature_responseCoding[row_index][i] = math.exp(sum_prob/len(row['TEXT'].split()))\n",
    "            row_index += 1\n",
    "    return text_feature_responseCoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a CountVectorizer with all the words that occured minimum 3 times in train data\n",
    "text_vectorizer = CountVectorizer(min_df=3)\n",
    "train_text_feature_onehotCoding = text_vectorizer.fit_transform(train_df['TEXT'])\n",
    "# getting all the feature names (words)\n",
    "train_text_features= text_vectorizer.get_feature_names()\n",
    "\n",
    "# train_text_feature_onehotCoding.sum(axis=0).A1 will sum every row and returns (1*number of features) vector\n",
    "train_text_fea_counts = train_text_feature_onehotCoding.sum(axis=0).A1\n",
    "\n",
    "# zip(list(text_features),text_fea_counts) will zip a word with its number of times it occured\n",
    "text_fea_dict = dict(zip(list(train_text_features),train_text_fea_counts))\n",
    "\n",
    "\n",
    "print(\"Total number of unique words in train data :\", len(train_text_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list = []\n",
    "# dict_list =[] contains 9 dictoinaries each corresponds to a class\n",
    "for i in range(1,10):\n",
    "    cls_text = train_df[train_df['Class']==i]\n",
    "    # build a word dict based on the words in that class\n",
    "    dict_list.append(extract_dictionary_paddle(cls_text))\n",
    "    # append it to dict_list\n",
    "\n",
    "# dict_list[i] is build on i'th  class text data\n",
    "# total_dict is buid on whole training text data\n",
    "total_dict = extract_dictionary_paddle(train_df)\n",
    "\n",
    "\n",
    "confuse_array = []\n",
    "for i in train_text_features:\n",
    "    ratios = []\n",
    "    max_val = -1\n",
    "    for j in range(0,9):\n",
    "        ratios.append((dict_list[j][i]+10 )/(total_dict[i]+90))\n",
    "    confuse_array.append(ratios)\n",
    "confuse_array = np.array(confuse_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#response coding of text features\n",
    "train_text_feature_responseCoding  = get_text_responsecoding(train_df)\n",
    "test_text_feature_responseCoding  = get_text_responsecoding(test_df)\n",
    "cv_text_feature_responseCoding  = get_text_responsecoding(cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/16202486\n",
    "# we convert each row values such that they sum to 1  \n",
    "train_text_feature_responseCoding = (train_text_feature_responseCoding.T/train_text_feature_responseCoding.sum(axis=1)).T\n",
    "test_text_feature_responseCoding = (test_text_feature_responseCoding.T/test_text_feature_responseCoding.sum(axis=1)).T\n",
    "cv_text_feature_responseCoding = (cv_text_feature_responseCoding.T/cv_text_feature_responseCoding.sum(axis=1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't forget to normalize every feature\n",
    "train_text_feature_onehotCoding = normalize(train_text_feature_onehotCoding, axis=0)\n",
    "\n",
    "# we use the same vectorizer that was trained on train data\n",
    "test_text_feature_onehotCoding = text_vectorizer.transform(test_df['TEXT'])\n",
    "# don't forget to normalize every feature\n",
    "test_text_feature_onehotCoding = normalize(test_text_feature_onehotCoding, axis=0)\n",
    "\n",
    "# we use the same vectorizer that was trained on train data\n",
    "cv_text_feature_onehotCoding = text_vectorizer.transform(cv_df['TEXT'])\n",
    "# don't forget to normalize every feature\n",
    "cv_text_feature_onehotCoding = normalize(cv_text_feature_onehotCoding, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/a/2258273/4084039\n",
    "sorted_text_fea_dict = dict(sorted(text_fea_dict.items(), key=lambda x: x[1] , reverse=True))\n",
    "sorted_text_occur = np.array(list(sorted_text_fea_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of words for a given frequency.\n",
    "print(Counter(sorted_text_occur))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets build the model with only ***text*** column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_log_error_array=[]\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(alpha=i, penalty='l2', loss='log', random_state=42)\n",
    "    clf.fit(train_text_feature_onehotCoding, y_train)\n",
    "    \n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(train_text_feature_onehotCoding, y_train)\n",
    "    predict_y = sig_clf.predict_proba(cv_text_feature_onehotCoding)\n",
    "    cv_log_error_array.append(log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "    print('For values of alpha = ', i, \"The log loss is:\",log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, cv_log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(cv_log_error_array,3)):\n",
    "    ax.annotate((alpha[i],np.round(txt,3)), (alpha[i],cv_log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha = np.argmin(cv_log_error_array)\n",
    "clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='log', random_state=42)\n",
    "clf.fit(train_text_feature_onehotCoding, y_train)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(train_text_feature_onehotCoding, y_train)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(train_text_feature_onehotCoding)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(cv_text_feature_onehotCoding)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The cross validation log loss is:\",log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(test_text_feature_onehotCoding)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(y_test, predict_y, labels=clf.classes_, eps=1e-15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check the overlap of text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intersec_text(df):\n",
    "    df_text_vec = CountVectorizer(min_df=3)\n",
    "    df_text_fea = df_text_vec.fit_transform(df['TEXT'])\n",
    "    df_text_features = df_text_vec.get_feature_names()\n",
    "\n",
    "    df_text_fea_counts = df_text_fea.sum(axis=0).A1\n",
    "    df_text_fea_dict = dict(zip(list(df_text_features),df_text_fea_counts))\n",
    "    len1 = len(set(df_text_features))\n",
    "    len2 = len(set(train_text_features) & set(df_text_features))\n",
    "    return len1,len2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len1,len2 = get_intersec_text(test_df)\n",
    "print(np.round((len2/len1)*100, 3), \"% of word of test data appeared in train data\")\n",
    "len1,len2 = get_intersec_text(cv_df)\n",
    "print(np.round((len2/len1)*100, 3), \"% of word of Cross Validation appeared in train data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, all 3 columns are going to be important.\n",
    "\n",
    "## Data prepration for Machine Learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create few functions which we will be using later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_log_loss(train_x, train_y, test_x, test_y,  clf):\n",
    "    clf.fit(train_x, train_y)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(train_x, train_y)\n",
    "    sig_clf_probs = sig_clf.predict_proba(test_x)\n",
    "    return log_loss(test_y, sig_clf_probs, eps=1e-15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function plots the confusion matrices given y_i, y_i_hat.\n",
    "def plot_confusion_matrix(test_y, predict_y):\n",
    "    C = confusion_matrix(test_y, predict_y)\n",
    "    \n",
    "    A =(((C.T)/(C.sum(axis=1))).T)\n",
    "    \n",
    "    B =(C/C.sum(axis=0)) \n",
    "    labels = [1,2,3,4,5,6,7,8,9]\n",
    "    # representing A in heatmap format\n",
    "    print(\"-\"*20, \"Confusion matrix\", \"-\"*20)\n",
    "    plt.figure(figsize=(20,7))\n",
    "    sns.heatmap(C, annot=True, cmap=\"YlGnBu\", fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"-\"*20, \"Precision matrix (Columm Sum=1)\", \"-\"*20)\n",
    "    plt.figure(figsize=(20,7))\n",
    "    sns.heatmap(B, annot=True, cmap=\"YlGnBu\", fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.show()\n",
    "    \n",
    "    # representing B in heatmap format\n",
    "    print(\"-\"*20, \"Recall matrix (Row sum=1)\", \"-\"*20)\n",
    "    plt.figure(figsize=(20,7))\n",
    "    sns.heatmap(A, annot=True, cmap=\"YlGnBu\", fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def predict_and_plot_confusion_matrix(train_x, train_y,test_x, test_y, clf):\n",
    "    clf.fit(train_x, train_y)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(train_x, train_y)\n",
    "    pred_y = sig_clf.predict(test_x)\n",
    "\n",
    "    # for calculating log_loss we willl provide the array of probabilities belongs to each class\n",
    "    print(\"Log loss :\",log_loss(test_y, sig_clf.predict_proba(test_x)))\n",
    "    # calculating the number of data points that are misclassified\n",
    "    print(\"Number of mis-classified points :\", np.count_nonzero((pred_y- test_y))/test_y.shape[0])\n",
    "    plot_confusion_matrix(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will be used just for naive bayes\n",
    "# for the given indices, we will print the name of the features\n",
    "# and we will check whether the feature present in the test point text or not\n",
    "def get_impfeature_names(indices, text, gene, var, no_features):\n",
    "    gene_count_vec = CountVectorizer()\n",
    "    var_count_vec = CountVectorizer()\n",
    "    text_count_vec = CountVectorizer(min_df=3)\n",
    "    \n",
    "    gene_vec = gene_count_vec.fit(train_df['Gene'])\n",
    "    var_vec  = var_count_vec.fit(train_df['Variation'])\n",
    "    text_vec = text_count_vec.fit(train_df['TEXT'])\n",
    "    \n",
    "    fea1_len = len(gene_vec.get_feature_names())\n",
    "    fea2_len = len(var_count_vec.get_feature_names())\n",
    "    \n",
    "    word_present = 0\n",
    "    for i,v in enumerate(indices):\n",
    "        if (v < fea1_len):\n",
    "            word = gene_vec.get_feature_names()[v]\n",
    "            yes_no = True if word == gene else False\n",
    "            if yes_no:\n",
    "                word_present += 1\n",
    "                print(i, \"Gene feature [{}] present in test data point [{}]\".format(word,yes_no))\n",
    "        elif (v < fea1_len+fea2_len):\n",
    "            word = var_vec.get_feature_names()[v-(fea1_len)]\n",
    "            yes_no = True if word == var else False\n",
    "            if yes_no:\n",
    "                word_present += 1\n",
    "                print(i, \"variation feature [{}] present in test data point [{}]\".format(word,yes_no))\n",
    "        else:\n",
    "            word = text_vec.get_feature_names()[v-(fea1_len+fea2_len)]\n",
    "            yes_no = True if word in text.split() else False\n",
    "            if yes_no:\n",
    "                word_present += 1\n",
    "                print(i, \"Text feature [{}] present in test data point [{}]\".format(word,yes_no))\n",
    "\n",
    "    print(\"Out of the top \",no_features,\" features \", word_present, \"are present in query point\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining all 3 features together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging gene, variance and text features\n",
    "\n",
    "# building train, test and cross validation data sets\n",
    "# a = [[1, 2], \n",
    "#      [3, 4]]\n",
    "# b = [[4, 5], \n",
    "#      [6, 7]]\n",
    "# hstack(a, b) = [[1, 2, 4, 5],\n",
    "#                [ 3, 4, 6, 7]]\n",
    "\n",
    "train_gene_var_onehotCoding = hstack((train_gene_feature_onehotCoding,train_variation_feature_onehotCoding))\n",
    "test_gene_var_onehotCoding = hstack((test_gene_feature_onehotCoding,test_variation_feature_onehotCoding))\n",
    "cv_gene_var_onehotCoding = hstack((cv_gene_feature_onehotCoding,cv_variation_feature_onehotCoding))\n",
    "\n",
    "train_x_onehotCoding = hstack((train_gene_var_onehotCoding, train_text_feature_onehotCoding)).tocsr()\n",
    "train_y = np.array(list(train_df['Class']))\n",
    "\n",
    "test_x_onehotCoding = hstack((test_gene_var_onehotCoding, test_text_feature_onehotCoding)).tocsr()\n",
    "test_y = np.array(list(test_df['Class']))\n",
    "\n",
    "cv_x_onehotCoding = hstack((cv_gene_var_onehotCoding, cv_text_feature_onehotCoding)).tocsr()\n",
    "cv_y = np.array(list(cv_df['Class']))\n",
    "\n",
    "\n",
    "train_gene_var_responseCoding = np.hstack((train_gene_feature_responseCoding,train_variation_feature_responseCoding))\n",
    "test_gene_var_responseCoding = np.hstack((test_gene_feature_responseCoding,test_variation_feature_responseCoding))\n",
    "cv_gene_var_responseCoding = np.hstack((cv_gene_feature_responseCoding,cv_variation_feature_responseCoding))\n",
    "\n",
    "train_x_responseCoding = np.hstack((train_gene_var_responseCoding, train_text_feature_responseCoding))\n",
    "test_x_responseCoding = np.hstack((test_gene_var_responseCoding, test_text_feature_responseCoding))\n",
    "cv_x_responseCoding = np.hstack((cv_gene_var_responseCoding, cv_text_feature_responseCoding))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"One hot encoding features :\")\n",
    "print(\"(number of data points * number of features) in train data = \", train_x_onehotCoding.shape)\n",
    "print(\"(number of data points * number of features) in test data = \", test_x_onehotCoding.shape)\n",
    "print(\"(number of data points * number of features) in cross validation data =\", cv_x_onehotCoding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Response encoding features :\")\n",
    "print(\"(number of data points * number of features) in train data = \", train_x_responseCoding.shape)\n",
    "print(\"(number of data points * number of features) in test data = \", test_x_responseCoding.shape)\n",
    "print(\"(number of data points * number of features) in cross validation data =\", cv_x_responseCoding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Machine Learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start the first model which is most suitable when we have lot of text column data. So, we will start with Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
    "alpha = [0.00001, 0.0001, 0.001, 0.1, 1, 10, 100,1000]\n",
    "cv_log_error_array = []\n",
    "for i in alpha:\n",
    "    print(\"for alpha =\", i)\n",
    "    clf = MultinomialNB(alpha=i)\n",
    "    clf.fit(train_x_onehotCoding, train_y)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(train_x_onehotCoding, train_y)\n",
    "    sig_clf_probs = sig_clf.predict_proba(cv_x_onehotCoding)\n",
    "    cv_log_error_array.append(log_loss(cv_y, sig_clf_probs, labels=clf.classes_, eps=1e-15))\n",
    "    # to avoid rounding error while multiplying probabilites we use log-probability estimates\n",
    "    print(\"Log Loss :\",log_loss(cv_y, sig_clf_probs)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.log10(alpha), cv_log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(cv_log_error_array,3)):\n",
    "    ax.annotate((alpha[i],str(txt)), (np.log10(alpha[i]),cv_log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.xticks(np.log10(alpha))\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha = np.argmin(cv_log_error_array)\n",
    "clf = MultinomialNB(alpha=alpha[best_alpha])\n",
    "clf.fit(train_x_onehotCoding, train_y)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(train_x_onehotCoding, train_y)\n",
    "\n",
    "\n",
    "predict_y = sig_clf.predict_proba(train_x_onehotCoding)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(cv_x_onehotCoding)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The cross validation log loss is:\",log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(test_x_onehotCoding)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(y_test, predict_y, labels=clf.classes_, eps=1e-15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing our Naive Bayes model with best found value of alpha on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB(alpha=alpha[best_alpha])\n",
    "clf.fit(train_x_onehotCoding, train_y)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(train_x_onehotCoding, train_y)\n",
    "sig_clf_probs = sig_clf.predict_proba(cv_x_onehotCoding)\n",
    "# to avoid rounding error while multiplying probabilites we use log-probability estimates\n",
    "print(\"Log Loss :\",log_loss(cv_y, sig_clf_probs))\n",
    "print(\"Number of missclassified point :\", np.count_nonzero((sig_clf.predict(cv_x_onehotCoding)- cv_y))/cv_y.shape[0])\n",
    "plot_confusion_matrix(cv_y, sig_clf.predict(cv_x_onehotCoding.toarray()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretability of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_point_index = 1\n",
    "no_feature = 100\n",
    "predicted_cls = sig_clf.predict(test_x_onehotCoding[test_point_index])\n",
    "print(\"Predicted Class :\", predicted_cls[0])\n",
    "print(\"Predicted Class Probabilities:\", np.round(sig_clf.predict_proba(test_x_onehotCoding[test_point_index]),4))\n",
    "print(\"Actual Class :\", test_y[test_point_index])\n",
    "indices = np.argsort(-clf.coef_)[predicted_cls-1][:,:no_feature]\n",
    "print(\"-\"*50)\n",
    "get_impfeature_names(indices[0], test_df['TEXT'].iloc[test_point_index],test_df['Gene'].iloc[test_point_index],test_df['Variation'].iloc[test_point_index], no_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at one more point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_point_index = 100\n",
    "no_feature = 100\n",
    "predicted_cls = sig_clf.predict(test_x_onehotCoding[test_point_index])\n",
    "print(\"Predicted Class :\", predicted_cls[0])\n",
    "print(\"Predicted Class Probabilities:\", np.round(sig_clf.predict_proba(test_x_onehotCoding[test_point_index]),4))\n",
    "print(\"Actual Class :\", test_y[test_point_index])\n",
    "indices = np.argsort(-clf.coef_)[predicted_cls-1][:,:no_feature]\n",
    "print(\"-\"*50)\n",
    "get_impfeature_names(indices[0], test_df['TEXT'].iloc[test_point_index],test_df['Gene'].iloc[test_point_index],test_df['Variation'].iloc[test_point_index], no_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So Naive Bayes not performing very badly but lets look at other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbour Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [5, 11, 15, 21, 31, 41, 51, 99]\n",
    "cv_log_error_array = []\n",
    "for i in alpha:\n",
    "    print(\"for alpha =\", i)\n",
    "    clf = KNeighborsClassifier(n_neighbors=i)\n",
    "    clf.fit(train_x_responseCoding, train_y)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(train_x_responseCoding, train_y)\n",
    "    sig_clf_probs = sig_clf.predict_proba(cv_x_responseCoding)\n",
    "    cv_log_error_array.append(log_loss(cv_y, sig_clf_probs, labels=clf.classes_, eps=1e-15))\n",
    "    # to avoid rounding error while multiplying probabilites we use log-probability estimates\n",
    "    print(\"Log Loss :\",log_loss(cv_y, sig_clf_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, cv_log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(cv_log_error_array,3)):\n",
    "    ax.annotate((alpha[i],str(txt)), (alpha[i],cv_log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha = np.argmin(cv_log_error_array)\n",
    "clf = KNeighborsClassifier(n_neighbors=alpha[best_alpha])\n",
    "clf.fit(train_x_responseCoding, train_y)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(train_x_responseCoding, train_y)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(train_x_responseCoding)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(cv_x_responseCoding)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The cross validation log loss is:\",log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(test_x_responseCoding)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(y_test, predict_y, labels=clf.classes_, eps=1e-15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it on testing dataset with our best alpha value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=alpha[best_alpha])\n",
    "predict_and_plot_confusion_matrix(train_x_responseCoding, train_y, cv_x_responseCoding, cv_y, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets look at few test points\n",
    "clf = KNeighborsClassifier(n_neighbors=alpha[best_alpha])\n",
    "clf.fit(train_x_responseCoding, train_y)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(train_x_responseCoding, train_y)\n",
    "\n",
    "test_point_index = 1\n",
    "predicted_cls = sig_clf.predict(test_x_responseCoding[0].reshape(1,-1))\n",
    "print(\"Predicted Class :\", predicted_cls[0])\n",
    "print(\"Actual Class :\", test_y[test_point_index])\n",
    "neighbors = clf.kneighbors(test_x_responseCoding[test_point_index].reshape(1, -1), alpha[best_alpha])\n",
    "print(\"The \",alpha[best_alpha],\" nearest neighbours of the test points belongs to classes\",train_y[neighbors[1][0]])\n",
    "print(\"Fequency of nearest points :\",Counter(train_y[neighbors[1][0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=alpha[best_alpha])\n",
    "clf.fit(train_x_responseCoding, train_y)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(train_x_responseCoding, train_y)\n",
    "\n",
    "test_point_index = 100\n",
    "\n",
    "predicted_cls = sig_clf.predict(test_x_responseCoding[test_point_index].reshape(1,-1))\n",
    "print(\"Predicted Class :\", predicted_cls[0])\n",
    "print(\"Actual Class :\", test_y[test_point_index])\n",
    "neighbors = clf.kneighbors(test_x_responseCoding[test_point_index].reshape(1, -1), alpha[best_alpha])\n",
    "print(\"the k value for knn is\",alpha[best_alpha],\"and the nearest neighbours of the test points belongs to classes\",train_y[neighbors[1][0]])\n",
    "print(\"Fequency of nearest points :\",Counter(train_y[neighbors[1][0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [10 ** x for x in range(-6, 3)]\n",
    "cv_log_error_array = []\n",
    "for i in alpha:\n",
    "    print(\"for alpha =\", i)\n",
    "    clf = SGDClassifier(class_weight='balanced', alpha=i, penalty='l2', loss='log', random_state=42)\n",
    "    clf.fit(train_x_onehotCoding, train_y)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(train_x_onehotCoding, train_y)\n",
    "    sig_clf_probs = sig_clf.predict_proba(cv_x_onehotCoding)\n",
    "    cv_log_error_array.append(log_loss(cv_y, sig_clf_probs, labels=clf.classes_, eps=1e-15))\n",
    "    # to avoid rounding error while multiplying probabilites we use log-probability estimates\n",
    "    print(\"Log Loss :\",log_loss(cv_y, sig_clf_probs)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, cv_log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(cv_log_error_array,3)):\n",
    "    ax.annotate((alpha[i],str(txt)), (alpha[i],cv_log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha = np.argmin(cv_log_error_array)\n",
    "clf = SGDClassifier(class_weight='balanced', alpha=alpha[best_alpha], penalty='l2', loss='log', random_state=42)\n",
    "clf.fit(train_x_onehotCoding, train_y)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(train_x_onehotCoding, train_y)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(train_x_onehotCoding)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(cv_x_onehotCoding)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The cross validation log loss is:\",log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(test_x_onehotCoding)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(y_test, predict_y, labels=clf.classes_, eps=1e-15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets test it on testing data using best alpha value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SGDClassifier(class_weight='balanced', alpha=alpha[best_alpha], penalty='l2', loss='log', random_state=42)\n",
    "predict_and_plot_confusion_matrix(train_x_onehotCoding, train_y, cv_x_onehotCoding, cv_y, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imp_feature_names(text, indices, removed_ind = []):\n",
    "    word_present = 0\n",
    "    tabulte_list = []\n",
    "    incresingorder_ind = 0\n",
    "    for i in indices:\n",
    "        if i < train_gene_feature_onehotCoding.shape[1]:\n",
    "            tabulte_list.append([incresingorder_ind, \"Gene\", \"Yes\"])\n",
    "        elif i< 18:\n",
    "            tabulte_list.append([incresingorder_ind,\"Variation\", \"Yes\"])\n",
    "        if ((i > 17) & (i not in removed_ind)) :\n",
    "            word = train_text_features[i]\n",
    "            yes_no = True if word in text.split() else False\n",
    "            if yes_no:\n",
    "                word_present += 1\n",
    "            tabulte_list.append([incresingorder_ind,train_text_features[i], yes_no])\n",
    "        incresingorder_ind += 1\n",
    "    print(word_present, \"most importent features are present in our query point\")\n",
    "    print(\"-\"*50)\n",
    "    print(\"The features that are most importent of the \",predicted_cls[0],\" class:\")\n",
    "    print (tabulate(tabulte_list, headers=[\"Index\",'Feature name', 'Present or Not']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing query point and doing interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tabulate import tabulate\n",
    "clf = SGDClassifier(class_weight='balanced', alpha=alpha[best_alpha], penalty='l2', loss='log', random_state=42)\n",
    "clf.fit(train_x_onehotCoding,train_y)\n",
    "test_point_index = 1\n",
    "no_feature = 500\n",
    "predicted_cls = sig_clf.predict(test_x_onehotCoding[test_point_index])\n",
    "print(\"Predicted Class :\", predicted_cls[0])\n",
    "print(\"Predicted Class Probabilities:\", np.round(sig_clf.predict_proba(test_x_onehotCoding[test_point_index]),4))\n",
    "print(\"Actual Class :\", test_y[test_point_index])\n",
    "indices = np.argsort(-clf.coef_)[predicted_cls-1][:,:no_feature]\n",
    "print(\"-\"*50)\n",
    "get_impfeature_names(indices[0], test_df['TEXT'].iloc[test_point_index],test_df['Gene'].iloc[test_point_index],test_df['Variation'].iloc[test_point_index], no_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_point_index = 100\n",
    "no_feature = 500\n",
    "predicted_cls = sig_clf.predict(test_x_onehotCoding[test_point_index])\n",
    "print(\"Predicted Class :\", predicted_cls[0])\n",
    "print(\"Predicted Class Probabilities:\", np.round(sig_clf.predict_proba(test_x_onehotCoding[test_point_index]),4))\n",
    "print(\"Actual Class :\", test_y[test_point_index])\n",
    "indices = np.argsort(-clf.coef_)[predicted_cls-1][:,:no_feature]\n",
    "print(\"-\"*50)\n",
    "get_impfeature_names(indices[0], test_df['TEXT'].iloc[test_point_index],test_df['Gene'].iloc[test_point_index],test_df['Variation'].iloc[test_point_index], no_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without class balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [10 ** x for x in range(-6, 1)]\n",
    "cv_log_error_array = []\n",
    "for i in alpha:\n",
    "    print(\"for alpha =\", i)\n",
    "    clf = SGDClassifier(alpha=i, penalty='l2', loss='log', random_state=42)\n",
    "    clf.fit(train_x_onehotCoding, train_y)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(train_x_onehotCoding, train_y)\n",
    "    sig_clf_probs = sig_clf.predict_proba(cv_x_onehotCoding)\n",
    "    cv_log_error_array.append(log_loss(cv_y, sig_clf_probs, labels=clf.classes_, eps=1e-15))\n",
    "    print(\"Log Loss :\",log_loss(cv_y, sig_clf_probs)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, cv_log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(cv_log_error_array,3)):\n",
    "    ax.annotate((alpha[i],str(txt)), (alpha[i],cv_log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha = np.argmin(cv_log_error_array)\n",
    "clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='log', random_state=42)\n",
    "clf.fit(train_x_onehotCoding, train_y)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(train_x_onehotCoding, train_y)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(train_x_onehotCoding)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(cv_x_onehotCoding)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The cross validation log loss is:\",log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(test_x_onehotCoding)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(y_test, predict_y, labels=clf.classes_, eps=1e-15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets test our model with best hyper param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='log', random_state=42)\n",
    "predict_and_plot_confusion_matrix(train_x_onehotCoding, train_y, cv_x_onehotCoding, cv_y, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing query point and interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='log', random_state=42)\n",
    "clf.fit(train_x_onehotCoding,train_y)\n",
    "test_point_index = 1\n",
    "no_feature = 500\n",
    "predicted_cls = sig_clf.predict(test_x_onehotCoding[test_point_index])\n",
    "print(\"Predicted Class :\", predicted_cls[0])\n",
    "print(\"Predicted Class Probabilities:\", np.round(sig_clf.predict_proba(test_x_onehotCoding[test_point_index]),4))\n",
    "print(\"Actual Class :\", test_y[test_point_index])\n",
    "indices = np.argsort(-clf.coef_)[predicted_cls-1][:,:no_feature]\n",
    "print(\"-\"*50)\n",
    "get_impfeature_names(indices[0], test_df['TEXT'].iloc[test_point_index],test_df['Gene'].iloc[test_point_index],test_df['Variation'].iloc[test_point_index], no_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [10 ** x for x in range(-5, 3)]\n",
    "cv_log_error_array = []\n",
    "for i in alpha:\n",
    "    print(\"for C =\", i)\n",
    "#     clf = SVC(C=i,kernel='linear',probability=True, class_weight='balanced')\n",
    "    clf = SGDClassifier( class_weight='balanced', alpha=i, penalty='l2', loss='hinge', random_state=42)\n",
    "    clf.fit(train_x_onehotCoding, train_y)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(train_x_onehotCoding, train_y)\n",
    "    sig_clf_probs = sig_clf.predict_proba(cv_x_onehotCoding)\n",
    "    cv_log_error_array.append(log_loss(cv_y, sig_clf_probs, labels=clf.classes_, eps=1e-15))\n",
    "    print(\"Log Loss :\",log_loss(cv_y, sig_clf_probs)) \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, cv_log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(cv_log_error_array,3)):\n",
    "    ax.annotate((alpha[i],str(txt)), (alpha[i],cv_log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_alpha = np.argmin(cv_log_error_array)\n",
    "# clf = SVC(C=i,kernel='linear',probability=True, class_weight='balanced')\n",
    "clf = SGDClassifier(class_weight='balanced', alpha=alpha[best_alpha], penalty='l2', loss='hinge', random_state=42)\n",
    "clf.fit(train_x_onehotCoding, train_y)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(train_x_onehotCoding, train_y)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(train_x_onehotCoding)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(cv_x_onehotCoding)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The cross validation log loss is:\",log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(test_x_onehotCoding)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(y_test, predict_y, labels=clf.classes_, eps=1e-15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing model with best alpha values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='hinge', random_state=42,class_weight='balanced')\n",
    "predict_and_plot_confusion_matrix(train_x_onehotCoding, train_y,cv_x_onehotCoding,cv_y, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Querying some correctly classified point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='hinge', random_state=42)\n",
    "clf.fit(train_x_onehotCoding,train_y)\n",
    "test_point_index = 1\n",
    "# test_point_index = 100\n",
    "no_feature = 500\n",
    "predicted_cls = sig_clf.predict(test_x_onehotCoding[test_point_index])\n",
    "print(\"Predicted Class :\", predicted_cls[0])\n",
    "print(\"Predicted Class Probabilities:\", np.round(sig_clf.predict_proba(test_x_onehotCoding[test_point_index]),4))\n",
    "print(\"Actual Class :\", test_y[test_point_index])\n",
    "indices = np.argsort(-clf.coef_)[predicted_cls-1][:,:no_feature]\n",
    "print(\"-\"*50)\n",
    "get_impfeature_names(indices[0], test_df['TEXT'].iloc[test_point_index],test_df['Gene'].iloc[test_point_index],test_df['Variation'].iloc[test_point_index], no_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with One hot encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [100,200,500,1000,2000]\n",
    "max_depth = [5, 10]\n",
    "cv_log_error_array = []\n",
    "for i in alpha:\n",
    "    for j in max_depth:\n",
    "        print(\"for n_estimators =\", i,\"and max depth = \", j)\n",
    "        clf = RandomForestClassifier(n_estimators=i, criterion='gini', max_depth=j, random_state=42, n_jobs=-1)\n",
    "        clf.fit(train_x_onehotCoding, train_y)\n",
    "        sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "        sig_clf.fit(train_x_onehotCoding, train_y)\n",
    "        sig_clf_probs = sig_clf.predict_proba(cv_x_onehotCoding)\n",
    "        cv_log_error_array.append(log_loss(cv_y, sig_clf_probs, labels=clf.classes_, eps=1e-15))\n",
    "        print(\"Log Loss :\",log_loss(cv_y, sig_clf_probs)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha = np.argmin(cv_log_error_array)\n",
    "clf = RandomForestClassifier(n_estimators=alpha[int(best_alpha/2)], criterion='gini', max_depth=max_depth[int(best_alpha%2)], random_state=42, n_jobs=-1)\n",
    "clf.fit(train_x_onehotCoding, train_y)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(train_x_onehotCoding, train_y)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(train_x_onehotCoding)\n",
    "print('For values of best estimator = ', alpha[int(best_alpha/2)], \"The train log loss is:\",log_loss(y_train, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(cv_x_onehotCoding)\n",
    "print('For values of best estimator = ', alpha[int(best_alpha/2)], \"The cross validation log loss is:\",log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(test_x_onehotCoding)\n",
    "print('For values of best estimator = ', alpha[int(best_alpha/2)], \"The test log loss is:\",log_loss(y_test, predict_y, labels=clf.classes_, eps=1e-15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets test it on testing data using best hyper param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=alpha[int(best_alpha/2)], criterion='gini', max_depth=max_depth[int(best_alpha%2)], random_state=42, n_jobs=-1)\n",
    "predict_and_plot_confusion_matrix(train_x_onehotCoding, train_y,cv_x_onehotCoding,cv_y, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_point_index = 10\n",
    "clf = RandomForestClassifier(n_estimators=alpha[int(best_alpha/2)], criterion='gini', max_depth=max_depth[int(best_alpha%2)], random_state=42, n_jobs=-1)\n",
    "clf.fit(train_x_onehotCoding, train_y)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(train_x_onehotCoding, train_y)\n",
    "\n",
    "test_point_index = 1\n",
    "no_feature = 100\n",
    "predicted_cls = sig_clf.predict(test_x_onehotCoding[test_point_index])\n",
    "print(\"Predicted Class :\", predicted_cls[0])\n",
    "print(\"Predicted Class Probabilities:\", np.round(sig_clf.predict_proba(test_x_onehotCoding[test_point_index]),4))\n",
    "print(\"Actual Class :\", test_y[test_point_index])\n",
    "indices = np.argsort(-clf.feature_importances_)\n",
    "print(\"-\"*50)\n",
    "get_impfeature_names(indices[:no_feature], test_df['TEXT'].iloc[test_point_index],test_df['Gene'].iloc[test_point_index],test_df['Variation'].iloc[test_point_index], no_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF with Response Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [10,50,100,200,500,1000]\n",
    "max_depth = [2,3,5,10]\n",
    "cv_log_error_array = []\n",
    "for i in alpha:\n",
    "    for j in max_depth:\n",
    "        print(\"for n_estimators =\", i,\"and max depth = \", j)\n",
    "        clf = RandomForestClassifier(n_estimators=i, criterion='gini', max_depth=j, random_state=42, n_jobs=-1)\n",
    "        clf.fit(train_x_responseCoding, train_y)\n",
    "        sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "        sig_clf.fit(train_x_responseCoding, train_y)\n",
    "        sig_clf_probs = sig_clf.predict_proba(cv_x_responseCoding)\n",
    "        cv_log_error_array.append(log_loss(cv_y, sig_clf_probs, labels=clf.classes_, eps=1e-15))\n",
    "        print(\"Log Loss :\",log_loss(cv_y, sig_clf_probs)) \n",
    "\n",
    "\n",
    "best_alpha = np.argmin(cv_log_error_array)\n",
    "clf = RandomForestClassifier(n_estimators=alpha[int(best_alpha/4)], criterion='gini', max_depth=max_depth[int(best_alpha%4)], random_state=42, n_jobs=-1)\n",
    "clf.fit(train_x_responseCoding, train_y)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(train_x_responseCoding, train_y)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(train_x_responseCoding)\n",
    "print('For values of best alpha = ', alpha[int(best_alpha/4)], \"The train log loss is:\",log_loss(y_train, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(cv_x_responseCoding)\n",
    "print('For values of best alpha = ', alpha[int(best_alpha/4)], \"The cross validation log loss is:\",log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(test_x_responseCoding)\n",
    "print('For values of best alpha = ', alpha[int(best_alpha/4)], \"The test log loss is:\",log_loss(y_test, predict_y, labels=clf.classes_, eps=1e-15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing model with best hyper param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=max_depth[int(best_alpha%4)], n_estimators=alpha[int(best_alpha/4)], criterion='gini', max_features='auto',random_state=42)\n",
    "predict_and_plot_confusion_matrix(train_x_responseCoding, train_y,cv_x_responseCoding,cv_y, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query the classified point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=alpha[int(best_alpha/4)], criterion='gini', max_depth=max_depth[int(best_alpha%4)], random_state=42, n_jobs=-1)\n",
    "clf.fit(train_x_responseCoding, train_y)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(train_x_responseCoding, train_y)\n",
    "\n",
    "\n",
    "test_point_index = 1\n",
    "no_feature = 27\n",
    "predicted_cls = sig_clf.predict(test_x_responseCoding[test_point_index].reshape(1,-1))\n",
    "print(\"Predicted Class :\", predicted_cls[0])\n",
    "print(\"Predicted Class Probabilities:\", np.round(sig_clf.predict_proba(test_x_responseCoding[test_point_index].reshape(1,-1)),4))\n",
    "print(\"Actual Class :\", test_y[test_point_index])\n",
    "indices = np.argsort(-clf.feature_importances_)\n",
    "print(\"-\"*50)\n",
    "for i in indices:\n",
    "    if i<9:\n",
    "        print(\"Gene is important feature\")\n",
    "    elif i<18:\n",
    "        print(\"Variation is important feature\")\n",
    "    else:\n",
    "        print(\"Text is important feature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Refer:http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "vclf = VotingClassifier(estimators=[('lr', sig_clf1), ('svc', sig_clf2), ('rf', sig_clf3)], voting='soft')\n",
    "vclf.fit(train_x_onehotCoding, train_y)\n",
    "print(\"Log loss (train) on the VotingClassifier :\", log_loss(train_y, vclf.predict_proba(train_x_onehotCoding)))\n",
    "print(\"Log loss (CV) on the VotingClassifier :\", log_loss(cv_y, vclf.predict_proba(cv_x_onehotCoding)))\n",
    "print(\"Log loss (test) on the VotingClassifier :\", log_loss(test_y, vclf.predict_proba(test_x_onehotCoding)))\n",
    "print(\"Number of missclassified point :\", np.count_nonzero((vclf.predict(test_x_onehotCoding)- test_y))/test_y.shape[0])\n",
    "plot_confusion_matrix(test_y=test_y, predict_y=vclf.predict(test_x_onehotCoding))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
